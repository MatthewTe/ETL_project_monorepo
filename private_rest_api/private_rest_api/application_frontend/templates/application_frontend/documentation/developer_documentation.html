{% extends 'application_frontend/documentation/api_documentation_homepage.html' %}
{% load static %}

{% block docs_sidebar %}
<li class="sidebar_list_object"><a href="#top"><h4>Developer Docs</h4></a></li>
<li class="sidebar_list_object"><a href="#docker-compose"><h4>Setting Up The Project</h4></a></li>
<li class="sidebar_list_object"><a href="#celery"><h4>Celery</h4></a></li>
<li class="sidebar_list_object"><a href="#databases"><h4>Backend Database</h4></a></li>
<li class="sidebar_list_object"><a href="#nginx"><h4>Nginx</h4></a></li>
<li class="sidebar_list_object"><a href="#gunicorn"><h4>Django Gunicorn</h4></a></li>
{% endblock docs_sidebar %}

{% block doc_content %}
<div class="documentation_section">
    <h1 id="top">Documentation for Developers</h1>
    <div>
        <p>Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat! Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat</p>    
    </div>
    
</div>

<div class="documentation_section">
    <h1 id="docker-compose">Setting up the project (Docker-Compose)</h1>
    <div>
        <p>At its core the project is stood up by a docker-compose file. There may be higher level orchestration tools that are used to manage the project in production such as Ansible or a a container orchestration system like Kubernetes or Docker Swarm but at its core all the services are started using the main docker-compose file.</p>    
    
        <pre>
            <code>
services:
  # PSQL Database:
  db:
    image: postgres:9.4
    container_name: db
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
    networks: 
      - rest_api_network

  # Redis Message Broker:
  redis:
    image: redis:2.8.19
    container_name: redis
    networks: 
      - rest_api_network
    command: redis-server 

  # Building the Django server:
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: web
    command: ["./run_web.sh"]
    depends_on:
      - db
    volumes:
      - .:/app # This should be mounted in the current directory. 
    networks: 
      - rest_api_network
  
  # Nginx server:
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    container_name: nginx
    networks:
      - rest_api_network
    ports: 
      - "80:80"
      - "81:81"
    depends_on:
      - web
      - worker
      - beat
      - flower
    restart: always

  # Celery Worker:
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_worker
    depends_on:
      - web
      - db
      - redis
    command: ["./run_celery_worker.sh"]
    volumes:
      - .:/app
    environment: 
      MAX_AUTOSCALE: 10
      MIN_AUTOSCALE: 4
    networks: 
      - rest_api_network
  
  # Celery Beat Scheduler:
  beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_beat
    depends_on:
      - web
      - db
      - redis
    command: ["./run_celery_beat.sh"]
    volumes:
      - .:/app
    networks:
      - rest_api_network

  # Flower Display:
  flower:
    build: 
      context: ./flower
      dockerfile: Dockerfile
    container_name: celery_flower
    command: ["./run_celery_flower.sh"]
    depends_on:
      - beat
      - worker
      - redis  
    environment:
      CELERY_BROKER_URL: redis://redis:6379
      CELERY_RESULT_BACKEND: redis://redis:6379
      FLOWER_OAUTH2_KEY: example_security_key
      FLOWER_OAUTH2_SECRET: example_oauth_secret
      FLOWER_OAUTH2_REDIRECT_URI: http://localhost:81/login
    networks:
      - rest_api_network

networks:
  rest_api_network:
            </code>
        </pre>
        
        <p>Typically components in the mono-repo are contained in a sub-directory that contains three main objects:</p>
        <ul>
            <li>The source code of the component (for example the actual django codebase or nginx server configuration)</li>
            <li>A Dockerfile that describes the image</li>
            <li>A bash script file that the docker-compose file executes after the container is built (It is important to note that because the .sh script needs to be execute inside the container a key function of the Dockerfile is to copy the .sh script into the built container image).</li>
        </ul>
        
        <p>An example of a components <code>Dockerfile</code> is:</p>   
        <pre>
            <code>
#########################################################
# The Dockerfile for building and initalizing the REST API
#########################################################
FROM python:3.8

# Creating non-root user to run in container:
RUN groupadd -g 999 django_user && useradd -r -u 999 -g django_user django_user

# The enviroment variable ensures that the python output is set straight
# to the terminal with out buffering it first
ENV PYTHONUNBUFFERED 1

# Copying the django site files into the container: 
COPY private_rest_api /private_rest_api
WORKDIR /private_rest_api

# Installing python packages:
RUN pip install --upgrade pip && pip install --no-cache-dir -r requirements.txt
#USER django_user

# Configuring and starting the Django Project via a bash script: 
ENTRYPOINT ["sh", "start_server.sh"]
            </code>
        </pre>

        <p>The docker-compose file starts all the necessary containers and connects them via an internal network currently called (for legacy reasons) the <code>rest_api_network</code>. The nginx proxy server (see below) is the only service externally exposed. All other connection/interaction between containers is done from within the network.</p>
        <p>Components like the databases are connected to volumes that allow for persistent storage outside of container creation/destruction (See below).</p>
        <p>You can check the <a href="https://github.com/MatthewTe/ETL_project_monorepo">main git repository</a> to see how each component is structured (code-Dockerfile-.sh script)</p>
    
</div>
    
</div>

<div class="documentation_section">
    <h1 id="celery">Scheduling processes for django through Celery</h1>
    <div>
        <p>The data ingestion in the project is done via scheduled processes that extract, transform and ingest external data on a predefined schedule. More documentation on how data ingestion functions operate with the API are available, but in this context it is sufficient to say that the django web server requires that processes be executed at desired intervals. The most natural way to accomplish this is through the use of the Celery task queue.</p>    
        
        <h3>Celery Workers</h3>
        <p>The celery worker that executes the tasks is run insides its own docker container built from the django web server Dockerfile.</p>
        
        <pre>
            <code>
  # Celery Worker:
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_worker
    depends_on:
      - web
      - db
      - redis
    command: ["./run_celery_worker.sh"]
    volumes:
      - .:/app
    environment: 
      MAX_AUTOSCALE: 10
      MIN_AUTOSCALE: 4
    networks: 
      - rest_api_network                
            </code>
        </pre>

        <p>Like the django server the workers are launched via a <code>.sh</code> script that is copied into the docker container and starts the worker daemon via the typical command <code>celery -A private_rest_api worker</code>. The worker is configured using environmental variables declared in the docker-compose file at runtime. Currently the only configuration allowed is to set the minimum and maximum number of workers in the pool via the two env variables:</p>
        <p><code>MAX_AUTOSCALE: 10</code></p>
        <p><code>MIN_AUTOSCALE: 4</code></p>
        <p>Aside from auto-scaling, specifying external destinations for the log and pid (<code>--logifle</code> , <code>--pidfile</code>,  <code>-—statedb</code>) files generated by the worker process is the next step though at the time of writing this has not been done.</p>
    
        <h3>Celery Beat</h3>
        <p>Once a pool of workers has been set up the next step was to configure and start the actual process scheduler that tells the workers when to execute the tasks in the queue. This is done via celery beat due to its direct integration with django and task scheduling through django models. Like the worker celery beat is run inside a docker container built from the django web Dockerfile:</p>
        <pre>
            <code>
  # Celery Beat Scheduler:
  beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_beat
    depends_on:
      - web
      - db
      - redis
    command: ["./run_celery_beat.sh"]
    volumes:
      - .:/app
    networks:
      - rest_api_network
            </code>
        </pre>
        <p>Also like the worker container the beat daemon is launched via an <code>.sh</code> script that is copied into the container. Currently this script only runs the generic <code>celery -A private_rest_api beat -l INFO  --schedule=django_celery_beat.schedulers:DatabaseScheduler</code> command as all configuration of the beat scheduler is done inside the django <code>settings.py</code> file.</p>
    
        <h3>Celery Flower Monitor</h3>
        <p>The third upstream process for celery is a flower instance - a tool that monitors the celery pool and keeps track of all workers and tasks they carry out. The same container - <code>.sh</code> script arrangement is again used (the Dockerfile is built from the <code>mher/flower</code> image and the environment variables used to configure the flower instance are as follows:</p>
        <p><code>CELERY_BROKER_URL</code></p>
        <p><code>CELERY_RESULT_BACKEND</code></p>
        <p><code>FLOWER_OAUTH2_KEY</code></p>
        <p><code>FLOWER_OAUTH2_SECRET</code></p>
        <p><code>FLOWER_OAUTH2_REDIRECT_URI</code></p>

        <p>The first two variables deal with pointing to the message broker/database used by all workers and are fairly self explanatory. The other env variables have to do with setting up an authentication system for the flower dashboard.</p>
    
        <pre>
            <code>
  flower:
    build: 
      context: ./flower
      dockerfile: Dockerfile
    container_name: celery_flower
    command: ["./run_celery_flower.sh"]
    depends_on:
      - beat
      - worker
      - redis  
    environment:
      CELERY_BROKER_URL: redis://redis:6379
      CELERY_RESULT_BACKEND: redis://redis:6379
      FLOWER_OAUTH2_KEY: example_security_key
      FLOWER_OAUTH2_SECRET: example_oauth_secret
      FLOWER_OAUTH2_REDIRECT_URI: http://localhost:81/login
    networks:
      - rest_api_network
            </code>
        </pre>
        
        <p>Flower uses Githubs OAuth system for authenticating users and that system is configured according to the (very limited) docs. Basically all the auth tokens and ids are defined by the env variables and the celery flower command in the <code>.sh</code> file is run with the <code>-auth_provider=flower.views.auth.GithubLoginHandler</code> and the <code>—auth=thegithubaccountemail@example.com</code> flags.</p>
    
        <pre>
            <code>
#!/bin/sh
sleep 20

celery flower --auth_provider=flower.views.auth.GithubLoginHandler --auth=thegithubaccountemail@example.com
            </code>
        </pre>
    
        <h3>Message Broker and Backend</h3>
        <p>As we are currently not intending to scale the celery scheduled ingestion process we do not need a data persistent backend or the ability to handle a large amount of messages. As such we used redis as both our message broker and celery backend. Here our redis instance is configured in our docker-compose file:</p>
        <pre>
            <code>
  # Redis Message Broker:
  redis:
    image: redis:2.8.19
    container_name: redis
    networks: 
      - rest_api_network
    command: redis-server 
            </code>
        </pre>        
    </div>
    
</div>

<div class="documentation_section">
    <h1 id="databases">Databases on the backend</h1>
    <p>Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat! Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat</p>    
</div>

<div class="documentation_section">
    <h1 id="nginx">Nginx as a reverse proxy</h1>
    <p>Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat! Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat</p>    
</div>

<div class="documentation_section">
    <h1 id="gunicorn">Running the django web server (Gunicorn)</h1>
    <p>Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat! Lorem ipsum, dolor sit amet consectetur adipisicing elit. Dolorem laudantium eligendi qui dolorum illum itaque consectetur labore maiores, quidem, saepe quos incidunt quam tempora doloribus aliquid architecto error minima fugiat</p>    
</div>
{% endblock doc_content %}
